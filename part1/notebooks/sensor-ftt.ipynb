{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06de378-0fe5-4d0f-83ac-f0bdac7b8691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.10/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5544efb2-c094-4649-9772-be92e60bd132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "from scipy.fft import fft\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "multiprocessing.set_start_method('fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad03e33f-b9a9-4e34-844e-a5b26b121b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('accelerometer',)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer(os.environ.get('KAFKA_TOPIC', \"accelerometer\"), \n",
    "                         auto_offset_reset = 'earliest',\n",
    "                         bootstrap_servers = os.environ.get('KAFKA_BROKER', 'broker1:9093').split(\",\"), \n",
    "                         group_id = os.environ.get('KAFKA_GROUP_ID', \"accelerometer-group\"),\n",
    "                         api_version = (0, 10), \n",
    "                         value_deserializer = json.loads,\n",
    "                         consumer_timeout_ms = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a27f52-bd9e-4862-8f3d-9a5995a70fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consume_messages(messages_by_key):\n",
    "    sys.stdout.write(\"Starting\\n\")\n",
    "    sys.stdout.flush()\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            for message in consumer:\n",
    "                if count == 0:\n",
    "                    # sys.stdout.write(f\"{str(message)}\\n\")\n",
    "                    sys.stdout.write(str(message))\n",
    "                    sys.stdout.flush()\n",
    "                if message.key not in messages_by_key:\n",
    "                    messages_by_key[message.key] = {}\n",
    "                    \n",
    "                messages_current_key = messages_by_key[message.key]\n",
    "\n",
    "                seconds = int(message.timestamp / 1000)\n",
    "                if seconds not in messages_current_key:\n",
    "                    messages_current_key[seconds] = []\n",
    "\n",
    "                messages_current_key_seconds = messages_current_key[seconds]\n",
    "\n",
    "                messages_current_key_seconds.append([\n",
    "                    message.timestamp, \n",
    "                    message.value.get('x'),\n",
    "                    message.value.get('y'), \n",
    "                    message.value.get('z')\n",
    "                    ])\n",
    "\n",
    "                sys.stdout.write(f\"\\rRead Message {count}\")\n",
    "                count += 1\n",
    "            # commit offsets so we won't get the same messages again\n",
    "            consumer.commit()\n",
    "        except Exception as ex:\n",
    "            logger.error('Exception in consuming message', exc_info=True)\n",
    "\n",
    "        time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ed3566-677b-4f6e-be88-ca08776e021b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_messages(messages_by_key):\n",
    "    while True:\n",
    "        # iterate over each key and group messages by seconds\n",
    "        # then, process all seconds except the newest one\n",
    "        for key in messages_by_key.keys():\n",
    "            seconds = sorted(messages_by_key[key].keys())\n",
    "            for second in seconds[:-1]:\n",
    "                # process messages in this second\n",
    "                # 1 order by timestamp\n",
    "                sorted_messages = sorted(messages_by_key[key][second], key=lambda x: x[0])\n",
    "                # 2 extract x, y, z and create numpy arrays\n",
    "                x = np.array([m[1] for m in sorted_messages])\n",
    "                y = np.array([m[2] for m in sorted_messages])\n",
    "                z = np.array([m[3] for m in sorted_messages])\n",
    "                # 3 compute fft\n",
    "                x_fft = fft(x, n=10)\n",
    "                y_fft = fft(y, n=10)\n",
    "                z_fft = fft(z, n=10)\n",
    "                # 4 log to console\n",
    "                print(f\"Key: {key}, Second: {second}, X: {x_fft}, Y: {y_fft}, Z: {z_fft}\")\n",
    "                # remove processed messages\n",
    "                del messages_by_key[key][second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae3203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=broker1:9093 <connecting> [IPv4 ('172.18.0.7', 9093)]>: connecting to broker1:9093 [('172.18.0.7', 9093) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=broker1:9093 <connecting> [IPv4 ('172.18.0.7', 9093)]>: Connection complete.\n",
      "INFO:kafka.cluster:Group coordinator for accelerometer-group is BrokerMetadata(nodeId='coordinator-3', host='broker3', port=9097, rack=None)\n",
      "INFO:kafka.coordinator:Discovered coordinator coordinator-3 for group accelerometer-group\n",
      "INFO:kafka.coordinator:Starting new heartbeat thread\n",
      "INFO:kafka.coordinator.consumer:Revoking previously assigned partitions set() for group accelerometer-group\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=broker3:9097 <connecting> [IPv4 ('172.18.0.6', 9097)]>: connecting to broker3:9097 [('172.18.0.6', 9097) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-3 host=broker3:9097 <connecting> [IPv4 ('172.18.0.6', 9097)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=broker1:9093 <connected> [IPv4 ('172.18.0.7', 9093)]>: Closing connection. \n",
      "INFO:kafka.coordinator:(Re-)joining group accelerometer-group\n"
     ]
    }
   ],
   "source": [
    "# start two processes, one for consuming messages and one for processing messages\n",
    "\n",
    "\n",
    "messages_by_key = multiprocessing.Manager().dict()\n",
    "\n",
    "p1 = multiprocessing.Process(target=consume_messages, args=(messages_by_key,))\n",
    "#p2 = multiprocessing.Process(target=process_messages, args=(messages_by_key,))\n",
    "p1.start()\n",
    "#p2.start()\n",
    "p1.join()\n",
    "p2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818e9ff-0967-4735-8256-8177349cec28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
